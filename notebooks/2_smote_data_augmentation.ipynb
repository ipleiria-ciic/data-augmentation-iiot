{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%reset -f  \n",
    "'generic imports'\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "# from IPython.display import display, clear_output\n",
    "\n",
    "'data processing and augmentation imports'\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.utils import shuffle\n",
    "from imblearn import over_sampling\n",
    "\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "from src import utils\n",
    "import importlib\n",
    "importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_train, file_test):\n",
    "    \n",
    "    train_data = pd.read_csv(file_train, low_memory=False)\n",
    "    test_data = pd.read_csv(file_test, low_memory=False)\n",
    "    \n",
    "    print(f\"Train data: \\n {train_data.shape[0]} rows and {train_data.shape[1]} columns.\")\n",
    "    print(f\"Test data:\\n {test_data.shape[0]} rows and {test_data.shape[1]} columns.\\n\")\n",
    "    \n",
    "    assert train_data.dtypes.equals(test_data.dtypes), \"Train and test data types are not the same\"\n",
    "    assert train_data.shape[1] == test_data.shape[1], \"Train and test data have different number of columns\"\n",
    "\n",
    "    print(\"Train and Test data types match:\")\n",
    "    print(pd.concat([train_data.dtypes, test_data.dtypes], axis=1, keys=['Train', 'Test']), \"\\n\")\n",
    "\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: \n",
      " 536515 rows and 48 columns.\n",
      "Test data:\n",
      " 381934 rows and 48 columns.\n",
      "\n",
      "Train and Test data types match:\n",
      "                             Train     Test\n",
      "arp.opcode                 float64  float64\n",
      "arp.hw.size                float64  float64\n",
      "icmp.checksum              float64  float64\n",
      "icmp.seq_le                float64  float64\n",
      "icmp.unused                float64  float64\n",
      "http.content_length        float64  float64\n",
      "http.request.method         object   object\n",
      "http.referer                object   object\n",
      "http.request.version        object   object\n",
      "http.response              float64  float64\n",
      "http.tls_port              float64  float64\n",
      "tcp.ack                    float64  float64\n",
      "tcp.ack_raw                float64  float64\n",
      "tcp.checksum               float64  float64\n",
      "tcp.connection.fin         float64  float64\n",
      "tcp.connection.rst         float64  float64\n",
      "tcp.connection.syn         float64  float64\n",
      "tcp.connection.synack      float64  float64\n",
      "tcp.flags                  float64  float64\n",
      "tcp.flags.ack              float64  float64\n",
      "tcp.len                    float64  float64\n",
      "tcp.seq                    float64  float64\n",
      "udp.stream                 float64  float64\n",
      "udp.time_delta             float64  float64\n",
      "dns.qry.name               float64  float64\n",
      "dns.qry.name.len            object   object\n",
      "dns.qry.qu                 float64  float64\n",
      "dns.qry.type               float64  float64\n",
      "dns.retransmission         float64  float64\n",
      "dns.retransmit_request     float64  float64\n",
      "dns.retransmit_request_in  float64  float64\n",
      "mqtt.conack.flags           object   object\n",
      "mqtt.conflag.cleansess     float64  float64\n",
      "mqtt.conflags              float64  float64\n",
      "mqtt.hdrflags              float64  float64\n",
      "mqtt.len                   float64  float64\n",
      "mqtt.msg_decoded_as        float64  float64\n",
      "mqtt.msgtype               float64  float64\n",
      "mqtt.proto_len             float64  float64\n",
      "mqtt.protoname              object   object\n",
      "mqtt.topic                  object   object\n",
      "mqtt.topic_len             float64  float64\n",
      "mqtt.ver                   float64  float64\n",
      "mbtcp.len                  float64  float64\n",
      "mbtcp.trans_id             float64  float64\n",
      "mbtcp.unit_id              float64  float64\n",
      "Attack_label                 int64    int64\n",
      "Attack_type                 object   object \n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_train, df_test = load_data('../data/EdgeIIot_train_100k.csv','../data/EdgeIIot_test.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack_type and encoded labels:\n",
      "\n",
      "Backdoor                0\n",
      "DDoS_HTTP               1\n",
      "DDoS_ICMP               2\n",
      "DDoS_TCP                3\n",
      "DDoS_UDP                4\n",
      "Fingerprinting          5\n",
      "MITM                    6\n",
      "Normal                  7\n",
      "Password                8\n",
      "Port_Scanning           9\n",
      "Ransomware              10\n",
      "SQL_injection           11\n",
      "Uploading               12\n",
      "Vulnerability_scanner   13\n",
      "XSS                     14\n"
     ]
    }
   ],
   "source": [
    "y_train = df_train['Attack_type']\n",
    "y_test = df_test['Attack_type']\n",
    "\n",
    "X_train = df_train.drop(['Attack_type', 'Attack_label'], axis=1)\n",
    "X_test = df_test.drop(['Attack_type', 'Attack_label'], axis=1)\n",
    "\n",
    "# label encode the target variable\n",
    "y_train_enc, y_test_enc, le = utils.encode_labels(y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical features to be encoded:\n",
      "\n",
      "mqtt.topic\n",
      "http.referer\n",
      "http.request.version\n",
      "dns.qry.name.len\n",
      "mqtt.conack.flags\n",
      "mqtt.protoname\n",
      "http.request.method\n",
      "\n",
      "Encoding complete.\n",
      "No of features before encoding: 46\n",
      "No of features after encoding: 85\n"
     ]
    }
   ],
   "source": [
    "X_train_enc, X_test_enc = utils.encode_categorical(X_train, X_test)\n",
    "\n",
    "# Verify that the column names of the one-hot encoded training and test datasets are identical\n",
    "assert X_train_enc.columns.equals(X_test_enc.columns), \"Train and test data have different columns after one-hot encoding\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMOTE augmentation instantiation\n",
    "smote = over_sampling.SMOTE(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No rows before SMOTE: 536,515\n",
      "No rows after SMOTE: 1,500,000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SMOTE augmentation\n",
    "X_train_sm, y_train_sm = smote.fit_resample(X_train_enc, y_train_enc)\n",
    "print(f\"No rows before SMOTE: {len(X_train):,}\\nNo rows after SMOTE: {len(X_train_sm):,}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE train data: 1500000 rows and 87 columns.\n"
     ]
    }
   ],
   "source": [
    "# df_train_smote reconstruction\n",
    "df_train_sm = pd.DataFrame(X_train_sm)\n",
    "df_train_sm.columns = X_train_enc.columns\n",
    "df_train_sm['Attack_label'] = y_train_sm\n",
    "# Add Attack_type column based on Attack_label column\n",
    "df_train_sm['Attack_type'] = le.inverse_transform(df_train_sm['Attack_label'])\n",
    "print(f\"SMOTE train data: {df_train_sm.shape[0]} rows and {df_train_sm.shape[1]} columns.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded Test data: 381934 rows and 87 columns.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# df_test_enc reconstruction\n",
    "df_test_enc = pd.DataFrame(X_test_enc)\n",
    "df_test_enc.columns = X_test_enc.columns\n",
    "df_test_enc['Attack_label'] = y_test_enc\n",
    "# Add Attack_type column based on Attack_label column\n",
    "df_test_enc['Attack_type'] = le.inverse_transform(df_test_enc['Attack_label'])\n",
    "print(f\"Encoded Test data: {df_test_enc.shape[0]} rows and {df_test_enc.shape[1]} columns.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert df_train_sm.columns.equals(df_test_enc.columns), \"Train and test data have different columns after one-hot encoding\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save df_train_sm and df_test_enc to csv files\n",
    "df_train_sm.to_csv('../data/EdgeIIot_train_smote_v2.csv', index=False)\n",
    "df_test_enc.to_csv('../data/EdgeIIot_test_enc_v2.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inovmineral",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
